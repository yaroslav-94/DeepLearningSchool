{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество строк 5282, количество признаков 20\n",
      "Количество строк 4225, количество признаков 48\n",
      "Количество строк (4225,)\n",
      "(4225, 48)\n",
      "(1057, 48)\n"
     ]
    }
   ],
   "source": [
    "# Числовые признаки\n",
    "num_cols = [\n",
    "    'ClientPeriod',\n",
    "    'MonthlySpending',\n",
    "    'TotalSpent'\n",
    "]\n",
    "\n",
    "# Категориальные признаки\n",
    "cat_cols = [\n",
    "    'Sex',\n",
    "    'IsSeniorCitizen',\n",
    "    'HasPartner',\n",
    "    'HasChild',\n",
    "    'HasPhoneService',\n",
    "    'HasMultiplePhoneNumbers',\n",
    "    'HasInternetService',\n",
    "    'HasOnlineSecurityService',\n",
    "    'HasOnlineBackup',\n",
    "    'HasDeviceProtection',\n",
    "    'HasTechSupportAccess',\n",
    "    'HasOnlineTV',\n",
    "    'HasMovieSubscription',\n",
    "    'HasContractPhone',\n",
    "    'IsBillingPaperless',\n",
    "    'PaymentMethod'\n",
    "]\n",
    "\n",
    "feature_cols = num_cols + cat_cols\n",
    "target_col = 'Churn'\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "PATH = r'C:\\Users\\user\\PycharmProjects\\DeepLearningSchool\\8.Algorithm_composition\\{}'\n",
    "data = pd.read_csv(PATH.format('train.csv'))\n",
    "features_labels = []\n",
    "print(f\"Количество строк {data.shape[0]}, количество признаков {data.shape[1]}\")\n",
    "\n",
    "# Чтение данных для обучения модели\n",
    "y = data['Churn']\n",
    "data.drop(['Churn'], inplace=True, axis=True)\n",
    "data['TotalSpent'] = data['TotalSpent'].replace(' ', '0')\n",
    "data['TotalSpent'] = data['TotalSpent'].astype(float)\n",
    "data['TotalSpent'] = data['TotalSpent'].replace(0, data['TotalSpent'].mean())\n",
    "\n",
    "# Чтение данных для предсказания\n",
    "data_predict = pd.read_csv(PATH.format('test.csv'))\n",
    "data_predict['TotalSpent'] = data_predict['TotalSpent'].replace(' ', '0')\n",
    "data_predict['TotalSpent'] = data_predict['TotalSpent'].astype(float)\n",
    "data_predict['TotalSpent'] = data_predict['TotalSpent'].replace(0, data['TotalSpent'].mean())\n",
    "X_predict = data_predict\n",
    "\n",
    "#LabelEncoder для категориальных признаков\n",
    "le = LabelEncoder()\n",
    "for s in cat_cols:\n",
    "    le.fit(data[s])\n",
    "    data[s+'_le'] = le.transform(data[s])\n",
    "    X_predict[s+'_le'] = le.transform(X_predict[s])\n",
    "    features_labels.append(s+'_le')\n",
    "\n",
    "# OneHotEncoder для категориальных признаков\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "for s in cat_cols:\n",
    "    ohe.fit(data[s].values.reshape(-1, 1))\n",
    "    \n",
    "    new_ohe_features = ohe.transform(X_predict[s].values.reshape(-1, 1)).toarray()\n",
    "    tmp = pd.DataFrame(new_ohe_features, columns=[s+'='+str(i) for i in range(new_ohe_features.shape[1])])\n",
    "    X_predict = pd.concat([X_predict, tmp], axis=1)\n",
    "    X_predict.drop([s], axis=1, inplace=True)\n",
    "    \n",
    "    new_ohe_features = ohe.transform(data[s].values.reshape(-1, 1)).toarray()\n",
    "    tmp = pd.DataFrame(new_ohe_features, columns=[s+'='+str(i) for i in range(new_ohe_features.shape[1])])\n",
    "    data = pd.concat([data, tmp], axis=1)\n",
    "    data.drop([s], axis=1, inplace=True)\n",
    "    \n",
    "    [features_labels.append(s+'='+str(i)) for i in range(new_ohe_features.shape[1])]\n",
    "\n",
    "# Нормализация числовых признаков\n",
    "scaler = StandardScaler()\n",
    "for i in num_cols:\n",
    "    scaler.fit(data[i].values.reshape(-1, 1))\n",
    "    \n",
    "    X_predict[i+'_ss'] = scaler.transform(X_predict[i].values.reshape(-1, 1))\n",
    "    X_predict.drop([i], axis=1, inplace=True)\n",
    "    \n",
    "    data[i+'_ss'] = scaler.transform(data[i].values.reshape(-1, 1))\n",
    "    data.drop([i], axis=1, inplace=True)\n",
    "    \n",
    "    features_labels.append(i+'_ss') \n",
    "\n",
    "# Разбивание выборки для обучения на тестовую и валидационную\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    data, y, stratify=y, random_state=42, test_size=0.2\n",
    ")\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "\n",
    "transformer = MaxAbsScaler().fit(X_train)\n",
    "X_train = pd.DataFrame(transformer.transform(X_train), columns=features_labels)\n",
    "X_valid = pd.DataFrame(transformer.transform(X_valid), columns=features_labels)\n",
    "\n",
    "\n",
    "# qt = QuantileTransformer(n_quantiles=1000, random_state=0, output_distribution='normal')\n",
    "# qt.fit(X_train, y_train)\n",
    "# X_train = pd.DataFrame(qt.transform(X_train), columns=features_labels)\n",
    "# X_valid = pd.DataFrame(qt.transform(X_valid), columns=features_labels)\n",
    "\n",
    "new_names = ['ClientPeriod_ss', 'MonthlySpending_ss', 'TotalSpent_ss']\n",
    "pf = PolynomialFeatures(interaction_only=True, degree=2)\n",
    "pf.fit(X_train[(new_names)])\n",
    "\n",
    "X_train_pf = pf.transform(X_train[(new_names)])\n",
    "X_valid_pf = pf.transform(X_valid[(new_names)])\n",
    "new_names_pf = [f'new_names_{i}' for i in range(X_train_pf.shape[1])]\n",
    "\n",
    "X_train_pf = pd.DataFrame(X_train_pf, columns=new_names_pf)\n",
    "X_valid_pf = pd.DataFrame(X_valid_pf, columns=new_names_pf)\n",
    "X_train = pd.concat([X_train, X_train_pf], axis=1)\n",
    "X_valid = pd.concat([X_valid, X_valid_pf], axis=1)\n",
    "X_train = X_train.drop(['new_names_0'], axis=1)\n",
    "X_valid = X_valid.drop(['new_names_0'], axis=1)\n",
    "\n",
    "# Лучшие результаты получены для моделей LogisticRegression и GradientBoostingClassifier при k=62\n",
    "selecter = SelectKBest(f_classif, k=48).fit(X_train, y_train)\n",
    "X_train = selecter.transform(X_train)\n",
    "X_valid = selecter.transform(X_valid)\n",
    "\n",
    "print(f\"Количество строк {X_train.shape[0]}, количество признаков {X_train.shape[1]}\")\n",
    "print(f\"Количество строк {y_train.shape}\")\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   18.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:   35.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of  15 | elapsed:    1.6s remaining:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  15 | elapsed:    2.6s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  15 | elapsed:   36.7s remaining:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  15 | elapsed:   39.3s remaining:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   55.2s finished\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn - best estimator:  StackingClassifier(cv=5,\n",
      "                   estimators=[('grid_rfc',\n",
      "                                Pipeline(memory=None,\n",
      "                                         steps=[('select',\n",
      "                                                 SelectFromModel(estimator=RandomForestClassifier(bootstrap=True,\n",
      "                                                                                                  ccp_alpha=0.0,\n",
      "                                                                                                  class_weight=None,\n",
      "                                                                                                  criterion='entropy',\n",
      "                                                                                                  max_depth=None,\n",
      "                                                                                                  max_features='auto',\n",
      "                                                                                                  max_leaf_nodes=None,\n",
      "                                                                                                  max_samples=None,\n",
      "                                                                                                  min_impurity_decrease=0.0,\n",
      "                                                                                                  min_impurity_split=None,\n",
      "                                                                                                  min_samples_leaf=1,\n",
      "                                                                                                  min_sam...\n",
      "                                              warm_start=False))],\n",
      "                   final_estimator=LogisticRegression(C=12,\n",
      "                                                      class_weight='balanced',\n",
      "                                                      dual=False,\n",
      "                                                      fit_intercept=True,\n",
      "                                                      intercept_scaling=1,\n",
      "                                                      l1_ratio=None,\n",
      "                                                      max_iter=50000,\n",
      "                                                      multi_class='auto',\n",
      "                                                      n_jobs=None, penalty='l2',\n",
      "                                                      random_state=None,\n",
      "                                                      solver='liblinear',\n",
      "                                                      tol=0.0001, verbose=0,\n",
      "                                                      warm_start=False),\n",
      "                   n_jobs=None, passthrough=False, stack_method='predict_proba',\n",
      "                   verbose=0)\n",
      "Предсказание класса через лучшие параметры параметры 0.8543922984356197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "# MLPClassifier - 0.8520\n",
    "\n",
    "X_train_mlpc = X_train.copy()\n",
    "y_train_mlpc = y_train.copy()\n",
    "X_valid_mlpc = X_valid.copy()\n",
    "y_valid_mlpc = y_valid.copy()\n",
    "\n",
    "parameters_mlpc = {\n",
    "    'activation': ['logistic'],\n",
    "    'solver': ['adam'],\n",
    "    'max_iter': [50, 100, 150],\n",
    "    'alpha': [0.0001, 0.0005],\n",
    "    'learning_rate': ['constant'],\n",
    "    'hidden_layer_sizes': [100, 150, 200],\n",
    "    'random_state': [57]\n",
    "}\n",
    "clf_mlpc = MLPClassifier()\n",
    "mlpc_grid = GridSearchCV(clf_mlpc, parameters_mlpc, cv=5, scoring='roc_auc', n_jobs=-1, verbose=3)\n",
    "mlpc_grid.fit(X_train_mlpc, y_train_mlpc)\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "# GaussianNB - 0.8294\n",
    "\n",
    "clf_gnb = GaussianNB()\n",
    "clf_gnb.fit(X_train, y_train)\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "# GradientBoostingClassifier - 0.8519\n",
    "\n",
    "pipe_gbc = Pipeline(steps=[\n",
    "        ('select', SelectFromModel(estimator=GradientBoostingClassifier(loss='exponential', \n",
    "                                                                        criterion='friedman_mse', \n",
    "                                                                        random_state=57))),\n",
    "        ('clf', GradientBoostingClassifier(loss='exponential', \n",
    "                                           criterion='friedman_mse', \n",
    "                                          random_state=57))\n",
    "])\n",
    "\n",
    "parameters_gbc = {\n",
    "        'clf__learning_rate': [0.05],\n",
    "        'clf__n_estimators': [200, 300, 400],\n",
    "        'clf__subsample': [1, 2, 3],\n",
    "        'clf__min_samples_leaf': [2, 3],\n",
    "        'clf__max_depth': [1, 2],\n",
    "        'clf__max_features': [None],\n",
    "        'clf__random_state': [57]\n",
    "        }\n",
    "\n",
    "grid_gbc = GridSearchCV(pipe_gbc, parameters_gbc, cv=5, scoring='roc_auc', n_jobs=-1, refit=True, verbose=1)\n",
    "grid_gbc.fit(X_train, y_train)\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "# LogisticRegression - 0.8491\n",
    "\n",
    "pipe_lr = Pipeline(steps=[\n",
    "        ('select', SelectFromModel(estimator=LogisticRegression(solver='saga', random_state=57))),\n",
    "        ('clf', LogisticRegression(solver='saga', random_state=57))\n",
    "])\n",
    "\n",
    "parameters_lr= {\n",
    "    'clf__penalty': ['l1'],\n",
    "    'clf__C': [20],\n",
    "    'clf__class_weight': [None],\n",
    "    'clf__max_iter': [50000],\n",
    "    'clf__random_state': [57],\n",
    "    'clf__solver': ['saga']\n",
    "}\n",
    "\n",
    "grid_lr = GridSearchCV(pipe_lr, parameters_lr, cv=5, scoring='roc_auc', n_jobs=-1, verbose=3)\n",
    "grid_lr.fit(X_train, y_train)\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "# RandomForestClassifier - 0.84906\n",
    "\n",
    "pipe_rfc = Pipeline(steps=[\n",
    "        ('select', SelectFromModel(estimator=RandomForestClassifier(criterion='entropy'))),\n",
    "        ('clf', RandomForestClassifier(criterion='entropy'))\n",
    "])\n",
    "\n",
    "parameters_rfc = {\n",
    "    'clf__n_estimators': [200, 500, 1000],\n",
    "    'clf__criterion': ['entropy'],\n",
    "    'clf__min_samples_leaf': [1],\n",
    "    'clf__max_features': ['sqrt'],\n",
    "    'clf__max_samples': [80]\n",
    "}\n",
    "\n",
    "grid_rfc = GridSearchCV(pipe_rfc, parameters_rfc, cv=5, scoring='roc_auc', n_jobs=-1, verbose=3)\n",
    "grid_rfc.fit(X_train, y_train)\n",
    "##############################################################################################\n",
    "\n",
    "estimators = [\n",
    "              ('grid_rfc', grid_rfc.best_estimator_),\n",
    "              ('grid_gbc', grid_gbc.best_estimator_),\n",
    "              ('clf_gnb', clf_gnb),\n",
    "              ('grid_lr', grid_lr.best_estimator_),\n",
    "              ('mlpc_grid', mlpc_grid.best_estimator_)\n",
    "]\n",
    "\n",
    "sc_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=5)\n",
    "parameters_sc_lr = {\n",
    "    'final_estimator__penalty': ['l2'],\n",
    "    'final_estimator__solver': ['liblinear'],\n",
    "    'final_estimator__class_weight': ['balanced'],\n",
    "    'final_estimator__C': [8, 10, 12],\n",
    "    'final_estimator__max_iter': [50000],\n",
    "    'stack_method': ['predict_proba']\n",
    "}\n",
    "grid_sc_sklearn_clf = GridSearchCV(sc_clf, parameters_sc_lr, cv=5, scoring='roc_auc', n_jobs=-1, verbose=3)\n",
    "grid_sc_sklearn_clf.fit(X_train, y_train)\n",
    "\n",
    "print('Sklearn - best estimator: ', grid_sc_sklearn_clf.best_estimator_)\n",
    "print(\"Предсказание класса через лучшие параметры параметры\", \n",
    "      roc_auc_score(y_valid, grid_sc_sklearn_clf.best_estimator_.predict_proba(X_valid)[:, 1]))\n",
    "##############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "#############################################################################################\n",
    "params_xgb = {\n",
    "        'min_child_weight': [5],\n",
    "        'gamma': [5],\n",
    "        'subsample': [0.1],\n",
    "        'colsample_bytree': [0.5, 0.55, 0.6, ],\n",
    "        'max_depth': [2]\n",
    "        }\n",
    "\n",
    "clf_xgb = XGBClassifier()\n",
    "xgb_grid = GridSearchCV(clf_xgb, params_xgb, cv=5, verbose=4, scoring='roc_auc', refit=True, n_jobs=-1)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "#############################################################################################\n",
    "\n",
    "\n",
    "#############################################################################################\n",
    "parametrs_lgb = {\n",
    "    'num_leaves': [6],\n",
    "   'max_depth': [4],\n",
    "   'class_weight': ['balanced'], \n",
    "   'random_state': [100],\n",
    "   'learning_rate': [0.05],\n",
    "   'n_estimators': [110]\n",
    "}\n",
    "\n",
    "clf_lgb = lgb.LGBMClassifier()\n",
    "lgb_grid = GridSearchCV(clf_lgb, parametrs_lgb, cv=5, verbose=4, scoring='roc_auc', refit=True, n_jobs=-1)\n",
    "lgb_grid.fit(X_train, y_train)\n",
    "#############################################################################################\n",
    "\n",
    "\n",
    "#############################################################################################\n",
    "parameters_lr= {\n",
    "    'penalty': ['elasticnet', 'l1', 'l2', 'none'],\n",
    "    'C': [0.01, 0.1, 1, 10, 20, 50],\n",
    "    'class_weight': [None],\n",
    "    'max_iter': [1000],\n",
    "    'solver': ['saga']\n",
    "}\n",
    "clf_lr = LogisticRegression()\n",
    "lr_grid = GridSearchCV(clf_lr, parameters_lr, cv=5, scoring='roc_auc', n_jobs=-1, verbose=3)\n",
    "lr_grid.fit(X_train, y_train)\n",
    "#############################################################################################\n",
    "\n",
    "\n",
    "#############################################################################################\n",
    "cbc_clf = CatBoostClassifier(iterations=400,\n",
    "                       depth=4,\n",
    "                       learning_rate=0.05,\n",
    "                       loss_function='Logloss',\n",
    "                       verbose=False,\n",
    "                       random_seed = 4,\n",
    "                       l2_leaf_reg = 40,\n",
    "                       eval_metric='AUC'\n",
    "                       )\n",
    "\n",
    "parametrs_cbc = {\n",
    "    'iterations': [160],\n",
    "    \"learning_rate\": [0.05],\n",
    "    'min_data_in_leaf': [6],\n",
    "    'depth': [5],\n",
    "    'l2_leaf_reg': [0]    \n",
    "}\n",
    "\n",
    "cbc_grid = GridSearchCV(cbc_clf, parametrs_cbc, cv=5, verbose=4, scoring='roc_auc', refit=True, n_jobs=-1)\n",
    "cbc_grid.fit(X_train, y_train)\n",
    "#############################################################################################\n",
    "\n",
    "estimators = [\n",
    "     ('xgb', xgb_grid.best_estimator_),\n",
    "     ('lgb', lgb_grid.best_estimator_),\n",
    "     ('cbc', cbc_grid.best_estimator_),\n",
    "    ('lr', lr_grid.best_estimator_)\n",
    "]\n",
    "\n",
    "sc_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=5)\n",
    "parameters_sc_lr = {\n",
    "    'final_estimator__C': [10, 1, 0.1],\n",
    "    'final_estimator__penalty': ['elasticnet'],\n",
    "    'final_estimator__solver': ['saga'],\n",
    "    'final_estimator__l1_ratio': [0.5, 0.9],\n",
    "    'stack_method': ['predict_proba']\n",
    "}\n",
    "gs_sc_estim_clf = GridSearchCV(sc_clf, parameters_sc_lr, cv=5, scoring='roc_auc', n_jobs=-1, verbose=3)\n",
    "gs_sc_estim_clf.fit(X_train, y_train)\n",
    "print('StackingClassifier - best estimator: ', gs_sc_estim_clf.best_estimator_)\n",
    "print(\"Предсказание вероятности \", roc_auc_score(y_valid, gs_sc_estim_clf.best_estimator_.predict_proba(X_valid)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "vk_clf = VotingClassifier(\n",
    "    estimators= [\n",
    "        ('grid_sc_sklearn_clf', grid_sc_sklearn_clf.best_estimator_),\n",
    "        ('xgb', xgb_grid.best_estimator_),\n",
    "        ('lgb', lgb_grid.best_estimator_),\n",
    "        ('gs_sc_estim_clf', gs_sc_estim_clf.best_estimator_),\n",
    "        ('cbc', cbc_grid.best_estimator_)\n",
    "    ],\n",
    "    voting='soft')\n",
    "\n",
    "parameters_vk = {\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "gs_vk_clf = GridSearchCV(estimator=vk_clf, param_grid=parameters_vk, cv=5, scoring='roc_auc', n_jobs=-1, verbose=3)\n",
    "gs_vk_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# submission = pd.DataFrame(gs_vk_clf.best_estimator_.predict_proba(X_predict)[:, 1], columns=[\"Churn\"])\n",
    "# submission.to_csv(PATH.format('my_submission_voiting.csv'), columns=[\"Churn\"])\n",
    "print('VotingClassifier - best estimator: ', gs_vk_clf.best_estimator_)\n",
    "print('VotingClassifier - best params: ', gs_vk_clf.best_params_)\n",
    "print(\"Предсказание \", roc_auc_score(y_valid, gs_vk_clf.best_estimator_.predict(X_valid)))\n",
    "print(\"Предсказание вероятности \", roc_auc_score(y_valid, gs_vk_clf.best_estimator_.predict_proba(X_valid)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(gs_vk_clf.best_estimator_.predict_proba(X_predict)[:, 1], columns=[\"Churn\"])\n",
    "submission.to_csv(PATH.format('my_submission_voiting.csv'), columns=[\"Churn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "t = time.time()\n",
    "PATH = r'C:\\Users\\user\\PycharmProjects\\DeepLearningSchool\\8.Algorithm_composition\\{}'\n",
    "\n",
    "##############################################################################################\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# Читаем данные\n",
    "data = pd.read_csv(PATH.format('train.csv'))\n",
    "print(f\"Количество строк {data.shape[0]}, количество признаков {data.shape[1]}\")\n",
    "y = data['Churn']\n",
    "data.drop(['Churn'], inplace=True, axis=True)\n",
    "data['TotalSpent'] = data['TotalSpent'].replace(' ', '0')\n",
    "data['TotalSpent'] = data['TotalSpent'].astype(float)\n",
    "data['TotalSpent'] = data['TotalSpent'].replace(0, data['TotalSpent'].mean())\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    data, y, stratify=y, random_state=42, test_size=0.2\n",
    ")\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "data_predict = pd.read_csv(PATH.format('test.csv'))\n",
    "data_predict['TotalSpent'] = data_predict['TotalSpent'].replace(' ', '0')\n",
    "data_predict['TotalSpent'] = data_predict['TotalSpent'].astype(float)\n",
    "data_predict['TotalSpent'] = data_predict['TotalSpent'].replace(0, data['TotalSpent'].mean())\n",
    "X_predict = data_predict.copy()\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "cat_cols = [\n",
    "    'Sex',\n",
    "    'IsSeniorCitizen',\n",
    "    'HasPartner',\n",
    "    'HasChild',\n",
    "    'HasPhoneService',\n",
    "    'HasMultiplePhoneNumbers',\n",
    "    'HasInternetService',\n",
    "    'HasOnlineSecurityService',\n",
    "    'HasOnlineBackup',\n",
    "    'HasDeviceProtection',\n",
    "    'HasTechSupportAccess',\n",
    "    'HasOnlineTV',\n",
    "    'HasMovieSubscription',\n",
    "    'HasContractPhone',\n",
    "    'IsBillingPaperless',\n",
    "    'PaymentMethod'\n",
    "]\n",
    "\n",
    "num_cols = [\n",
    "    'ClientPeriod',\n",
    "    'MonthlySpending',\n",
    "    'TotalSpent'\n",
    "]\n",
    "\n",
    "features_labels = []\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "### LabelEncoder для категориальных признаков\n",
    "\n",
    "le = LabelEncoder()\n",
    "for s in cat_cols:\n",
    "    le.fit(data[s])\n",
    "    data[s+'_le'] = le.transform(data[s])\n",
    "    X_predict[s+'_le'] = le.transform(X_predict[s])\n",
    "    features_labels.append(s+'_le')\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "### OneHotEncoder для категориальных признаков\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "for s in cat_cols:\n",
    "    ohe.fit(data[s].values.reshape(-1, 1))\n",
    "    \n",
    "    new_ohe_features = ohe.transform(X_predict[s].values.reshape(-1, 1)).toarray()\n",
    "    tmp = pd.DataFrame(new_ohe_features, columns=[s+'='+str(i) for i in range(new_ohe_features.shape[1])])\n",
    "    X_predict = pd.concat([X_predict, tmp], axis=1)\n",
    "    X_predict.drop([s], axis=1, inplace=True)\n",
    "    \n",
    "    new_ohe_features = ohe.transform(data[s].values.reshape(-1, 1)).toarray()\n",
    "    tmp = pd.DataFrame(new_ohe_features, columns=[s+'='+str(i) for i in range(new_ohe_features.shape[1])])\n",
    "    data = pd.concat([data, tmp], axis=1)\n",
    "    data.drop([s], axis=1, inplace=True)\n",
    "    \n",
    "    [features_labels.append(s+'='+str(i)) for i in range(new_ohe_features.shape[1])]\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "### Нормализация числовых признаков\n",
    "scaler = StandardScaler()\n",
    "for i in num_cols:\n",
    "    scaler.fit(data[i].values.reshape(-1, 1))\n",
    "    \n",
    "    X_predict[i+'_ss'] = scaler.transform(X_predict[i].values.reshape(-1, 1))\n",
    "    X_predict.drop([i], axis=1, inplace=True)\n",
    "    \n",
    "    data[i+'_ss'] = scaler.transform(data[i].values.reshape(-1, 1))\n",
    "    data.drop([i], axis=1, inplace=True)\n",
    "    \n",
    "    features_labels.append(i+'_ss') \n",
    "##############################################################################################\n",
    "\n",
    "##############################################################################################\n",
    "cbc = CatBoostClassifier(iterations=400,\n",
    "                       depth=4,\n",
    "                       learning_rate=0.05,\n",
    "                       loss_function='Logloss',\n",
    "                       verbose=False,\n",
    "                       cat_features=cat_cols,\n",
    "                       random_seed = 4,\n",
    "                       l2_leaf_reg = 40,\n",
    "                       eval_metric='AUC'\n",
    "                       )\n",
    "\n",
    "parametrs_cbc = {\n",
    "    'iterations': [160, ],\n",
    "    \"learning_rate\": [0.05, ],\n",
    "    'min_data_in_leaf': [6,],\n",
    "    'depth': [5,],\n",
    "    'l2_leaf_reg': [0, ]    \n",
    "}\n",
    "\n",
    "cb_grid = GridSearchCV(cbc, parametrs_cbc, cv=5, verbose=4, scoring='roc_auc', refit=True, n_jobs=-1)\n",
    "cb_grid.fit(X_train, y_train)\n",
    "# print(\"CatBoostClassifier\")\n",
    "# print(\"Предсказание класса \", roc_auc_score(y_valid, cb_grid.best_estimator_.predict(X_valid)))\n",
    "# print(\"Предсказание класса через лучшие параметры параметры\", roc_auc_score(y_valid, cb_grid.best_estimator_.predict(X_valid)))\n",
    "# print(\"Предсказание вероятности \", roc_auc_score(y_valid, cb_grid.predict_proba(X_valid)[:, 1]))\n",
    "# print(\"Лучшие параметры \", cb_grid.best_params_)\n",
    "\n",
    "# submission = pd.DataFrame(cb_grid.best_estimator_.predict_proba(data_predict)[:, 1], columns=[\"Churn\"])\n",
    "# submission.to_csv(PATH.format('my_submission_catboost.csv'), columns=[\"Churn\"])\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "parametrs_lgb = {\n",
    "    'num_leaves': [5],\n",
    "   'max_depth': [4],\n",
    "   'class_weight': ['balanced'], \n",
    "   'learning_rate': [0.05],\n",
    "    'subsample_for_bin': [200],\n",
    "   'n_estimators': [115]\n",
    "}\n",
    "\n",
    "\n",
    "X_train_lgb, X_valid_lgb, y_train_lgb, y_valid_lgb = train_test_split(\n",
    "    data, y, stratify=y, random_state=42, test_size=0.2\n",
    ")\n",
    "clf_lgb = lgb.LGBMClassifier()\n",
    "lgb_grid = GridSearchCV(clf_lgb, parametrs_lgb, cv=5, verbose=4, scoring='roc_auc', refit=True, n_jobs=-1)\n",
    "lgb_grid.fit(X_train_lgb, y_train_lgb)\n",
    "# print(\"LGBMClassifier\")\n",
    "# print(\"Предсказание класса через лучшие параметры параметры\", \n",
    "#       roc_auc_score(y_valid_lgb, lgb_grid.best_estimator_.predict(X_valid_lgb)))\n",
    "\n",
    "# submission = pd.DataFrame(lgb_grid.best_estimator_.predict_proba(X_predict)[:, 1], columns=[\"Churn\"])\n",
    "# submission.to_csv(PATH.format('my_submission_lgbm.csv'), columns=[\"Churn\"])\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "parameters_mlpc = {\n",
    "    'activation': ['identity'],\n",
    "    'solver': ['lbfgs'],\n",
    "    'max_iter': [110],\n",
    "    'hidden_layer_sizes': [5]\n",
    "}\n",
    "\n",
    "mlpc_clf = MLPClassifier()\n",
    "gs_mlpc_clf = GridSearchCV(mlpc_clf, parameters_mlpc, cv=5, scoring='roc_auc', n_jobs=-1, verbose=3)\n",
    "gs_mlpc_clf.fit(X_train_lgb, y_train_lgb)\n",
    "# print('StackingClassifier - best estimator: ', gs_mlpc_clf.best_estimator_)\n",
    "# print(\"MLPClassifier - best predict: \", roc_auc_score(y_valid_xgb, gs_mlpc_clf.predict_proba(X_valid_xgb)[:, 1]))\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "params_xgb = {\n",
    "        'min_child_weight': [5],\n",
    "        'gamma': [5],\n",
    "        'subsample': [0.1],\n",
    "        'colsample_bytree': [0.5, 0.55, 0.6],\n",
    "        'max_depth': [2]\n",
    "        }\n",
    "X_train_xgb, X_valid_xgb, y_train_xgb, y_valid_xgb = train_test_split(\n",
    "    data, y, stratify=y, random_state=42, test_size=0.2\n",
    ")\n",
    "clf_xgb = XGBClassifier()\n",
    "xgb_grid = GridSearchCV(clf_xgb, params_xgb, cv=5, verbose=4, scoring='roc_auc', refit=True, n_jobs=-1)\n",
    "xgb_grid.fit(X_train_xgb, y_train_xgb)\n",
    "# print(\"XGBClassifier\")\n",
    "# print(\"Предсказание класса через лучшие параметры параметры\", roc_auc_score(y_valid_xgb, xgb_grid.best_estimator_.predict(X_valid_xgb)))\n",
    "# print(\"Предсказание вероятности \", roc_auc_score(y_valid_xgb, xgb_grid.best_estimator_.predict_proba(X_valid_xgb)[:, 1]))\n",
    "# print(\"Лучшие параметры \", xgb_grid.best_params_)\n",
    "\n",
    "# submission = pd.DataFrame(xgb_grid.best_estimator_.predict_proba(X_predict)[:, 1], columns=[\"Churn\"])\n",
    "# submission.to_csv(PATH.format('my_submission_xgb.csv'), columns=[\"Churn\"])\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "estimators = [\n",
    "     ('xgb', xgb_grid.best_estimator_),\n",
    "     ('lgb', lgb_grid.best_estimator_),\n",
    "     ('mplpc', gs_mlpc_clf.best_estimator_)\n",
    "#      ('cb', cb_grid.best_estimator_)\n",
    "]\n",
    "\n",
    "\n",
    "sc_clf = StackingClassifier(estimators=estimators, final_estimator=MLPClassifier(), cv=5)\n",
    "parameters_sc_lr = {\n",
    "    'final_estimator__activation': ['logistic'],\n",
    "    'final_estimator__solver': ['lbfgs'],\n",
    "    'final_estimator__hidden_layer_sizes': [100],\n",
    "    'stack_method': ['predict_proba']\n",
    "}\n",
    "gs_sc_clf = GridSearchCV(sc_clf, parameters_sc_lr, cv=5, scoring='roc_auc', n_jobs=-1, verbose=3)\n",
    "gs_sc_clf.fit(X_train_lgb, y_train_lgb)\n",
    "\n",
    "# End estimate. Writing some info \n",
    "submission = pd.DataFrame(gs_sc_clf.best_estimator_.predict_proba(X_predict)[:, 1], columns=[\"Churn\"])\n",
    "submission.to_csv(PATH.format('my_submission_stack.csv'), columns=[\"Churn\"])\n",
    "print('StackingClassifier - best estimator: ', gs_sc_clf.best_estimator_)\n",
    "print('StackingClassifier - best params: ', gs_sc_clf.best_params_)\n",
    "print(\"Предсказание вероятности \", roc_auc_score(y_valid_xgb, gs_sc_clf.best_estimator_.predict_proba(X_valid_xgb)[:, 1]))\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "\n",
    "vk_clf = VotingClassifier(\n",
    "    estimators= [\n",
    "        ('xgb', xgb_grid.best_estimator_),\n",
    "#         ('lgb', lgb_grid.best_estimator_),\n",
    "#         ('mplpc', gs_mlpc_clf.best_estimator_)\n",
    "#         ('cb', cb_grid.best_estimator_)\n",
    "    ],\n",
    "    voting='soft')\n",
    "parameters_vk = {\n",
    "#     'estimator__voting': ['hard','soft'],\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "gs_vk_clf = GridSearchCV(estimator=vk_clf, param_grid=parameters_vk, cv=5, scoring='roc_auc', n_jobs=-1, verbose=3)\n",
    "gs_vk_clf.fit(X_train_lgb, y_train_lgb)\n",
    "\n",
    "\n",
    "submission = pd.DataFrame(gs_vk_clf.best_estimator_.predict_proba(X_predict)[:, 1], columns=[\"Churn\"])\n",
    "submission.to_csv(PATH.format('my_submission_voiting.csv'), columns=[\"Churn\"])\n",
    "print('VotingClassifier - best estimator: ', gs_vk_clf.best_estimator_)\n",
    "print('VotingClassifier - best params: ', gs_vk_clf.best_params_)\n",
    "print(\"Предсказание вероятности \", roc_auc_score(y_valid_xgb, gs_vk_clf.best_estimator_.predict_proba(X_valid_xgb)[:, 1]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "##############################################################################################\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "##############################################################################################\n",
    "# LogisticRegression\n",
    "parameters_lr= {\n",
    "    'penalty': ['l1'],\n",
    "    'C': [10],\n",
    "    'class_weight': [None],\n",
    "    'max_iter': [1000],\n",
    "    'solver': ['saga']\n",
    "}\n",
    "clf_lr = LogisticRegression()\n",
    "gs_lr_clf = GridSearchCV(clf_lr, parameters_lr, cv=5, scoring='roc_auc', n_jobs=-1, verbose=3)\n",
    "gs_lr_clf.fit(X_train_lgb, y_train_lgb)\n",
    "print('LogisticRegression - best estimator: ', gs_sc_clf.best_estimator_)\n",
    "print(\"Предсказание вероятности \", roc_auc_score(y_valid_lgb, gs_lr_clf.best_estimator_.predict_proba(X_valid_lgb)[:, 1]))\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "# GaussianNB\n",
    "clf_gnb = GaussianNB()\n",
    "clf_gnb.fit(X_train_lgb, y_train_lgb)\n",
    "print('GaussianNB')\n",
    "print(\"Предсказание вероятности \", roc_auc_score(y_valid_lgb, clf_gnb.predict_proba(X_valid_lgb)[:, 1]))\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "# RandomForestClassifier\n",
    "parameters_rfc = {\n",
    "    'n_estimators': [10, 50, 100, 150, 200],\n",
    "    'criterion': ['gini','entropy'],\n",
    "    'min_samples_leaf': [1, 5, 10, 15, 20],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap':[False],\n",
    "    'max_samples': [5, 10, 15, 20]\n",
    "}\n",
    "\n",
    "clf_rfc = RandomForestClassifier()\n",
    "gs_rfc_clf = GridSearchCV(clf_lr, parameters_lr, cv=5, scoring='roc_auc', n_jobs=-1, verbose=3)\n",
    "gs_rfc_clf.fit(X_train_lgb, y_train_lgb)\n",
    "\n",
    "print('RandomForestClassifier - best estimator: ', gs_sc_clf.best_estimator_)\n",
    "print(\"Предсказание вероятности \", roc_auc_score(y_valid_lgb, gs_rfc_clf.best_estimator_.predict_proba(X_valid_lgb)[:, 1]))\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "estimators = [\n",
    "     ('lr', gs_lr_clf.best_estimator_),\n",
    "    ('xgb', xgb_grid.best_estimator_),\n",
    "     ('lgb', lgb_grid.best_estimator_),\n",
    "#      ('gnb', clf_gnb),\n",
    "     ('rfc', gs_rfc_clf.best_estimator_)\n",
    "]\n",
    "\n",
    "\n",
    "sc_clf = StackingClassifier(estimators=estimators, final_estimator=MLPClassifier(), cv=5)\n",
    "parameters_sc_lr = {\n",
    "#     'final_estimator__activation': ['logistic'],\n",
    "#     'final_estimator__solver': ['lbfgs'],\n",
    "#     'final_estimator__hidden_layer_sizes': [100],\n",
    "    'stack_method': ['predict_proba']\n",
    "}\n",
    "gs_sc_clf = GridSearchCV(sc_clf, parameters_sc_lr, cv=5, scoring='roc_auc', n_jobs=-1, verbose=3)\n",
    "gs_sc_clf.fit(X_train_lgb, y_train_lgb)\n",
    "submission = pd.DataFrame(gs_sc_clf.best_estimator_.predict_proba(X_predict)[:, 1], columns=[\"Churn\"])\n",
    "submission.to_csv(PATH.format('my_submission_stack.csv'), columns=[\"Churn\"])\n",
    "print('StackingClassifier - best estimator: ', gs_sc_clf.best_estimator_)\n",
    "print('StackingClassifier - best params: ', gs_sc_clf.best_params_)\n",
    "print(\"Предсказание вероятности \", roc_auc_score(y_valid_xgb, gs_sc_clf.best_estimator_.predict_proba(X_valid_xgb)[:, 1]))\n",
    "print(f'How long: {\"%.2f\" % (time.time()-t)}, s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
